{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "vPI0US0cwYgK",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "64918473-ee42-4b22-d7e5-bce18b663752"
      },
      "outputs": [],
      "source": [
        "import fsspec\n",
        "import pandas as pd\n",
        "\n",
        "root_dir = 'abfss://lakebeehaven@beehaven.dfs.core.windows.net'\n",
        "source = root_dir+\"gold/processing/\"\n",
        "\n",
        "# orgainize silver data by location\n",
        "silver_dfs = {\n",
        "    \"schwartau\": pd.DataFrame(),\n",
        "    \"wurzburg\": pd.DataFrame()\n",
        "}\n",
        "# empty list to hold merged DataFrames\n",
        "gold_dfs = []\n",
        "\n",
        "# list files in source\n",
        "fs = fsspec.filesystem(\"abfs\")\n",
        "file_list_longform = fs.ls(source)\n",
        "file_list = [file.rsplit(\"/\", maxsplit=1)[1] for file in file_list_longform]\n",
        "\n",
        "for file in file_list:\n",
        "    # skip \"hidden\" files\n",
        "    if file.startswith(\".\"):\n",
        "        continue\n",
        "\n",
        "    print(f\"processing {file}\")\n",
        "    df = pd.read_parquet(source+file, filesystem=fs)\n",
        "    location = file.split(\"_\")[0]\n",
        "\n",
        "    # temperature and humidity come from hive data and weather station: clarify source\n",
        "    if df.shape[1] == 2:\n",
        "        if \"temperature\" in df.columns:\n",
        "            df.columns = [\"timestamp\", \"temperature_hive\"]\n",
        "        elif \"humidity\" in df.columns:\n",
        "            df.columns = [\"timestamp\", \"humidity_hive\"]\n",
        "\n",
        "    if silver_dfs[location].empty:\n",
        "        silver_dfs[location] = df.copy()\n",
        "    else:\n",
        "        silver_dfs[location] = silver_dfs[location].merge(df, on=\"timestamp\", how=\"outer\")\n",
        "\n",
        "for loc in silver_dfs:\n",
        "    # skip locations with no DataFrames\n",
        "    if silver_dfs[loc].empty:\n",
        "        continue\n",
        "    # add location to DataFrames\n",
        "    silver_dfs[loc][\"location\"] = loc\n",
        "    silver_dfs[loc][\"location\"] = silver_dfs[loc][\"location\"].astype(\"category\")\n",
        "    # sort DataFrame by timestamps\n",
        "    silver_dfs[loc] = silver_dfs[loc].sort_values(by=\"timestamp\")\n",
        "\n",
        "gold = (\n",
        "    # combine silver DataFrames\n",
        "    pd.concat((silver_dfs[\"schwartau\"], silver_dfs[\"wurzburg\"]), ignore_index=True)\n",
        "    # set stardard column order\n",
        "    [['timestamp', 'location', 'flow_out', 'flow_in',\n",
        "       'temperature_hive', 'humidity_hive', 'weight', 'precipitation', 'pressure_msl',\n",
        "       'sunshine', 'temperature', 'wind_direction', 'wind_speed',\n",
        "       'cloud_cover', 'dew_point', 'relative_humidity', 'wind_gust_direction',\n",
        "       'wind_gust_speed', 'solar', 'precipitation_source_distance',\n",
        "       'pressure_msl_source_distance', 'sunshine_source_distance',\n",
        "       'temperature_source_distance', 'wind_direction_source_distance',\n",
        "       'wind_speed_source_distance', 'cloud_cover_source_distance',\n",
        "       'dew_point_source_distance', 'relative_humidity_source_distance',\n",
        "       'visibility_source_distance', 'wind_gust_direction_source_distance',\n",
        "       'wind_gust_speed_source_distance', 'solar_source_distance']]\n",
        ")\n",
        "gold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "lxLSppUVwYgN",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "c9ca1dbc-4f33-4f8d-ec67-21a9059216cc"
      },
      "outputs": [],
      "source": [
        "gold.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XcY8snPvwYgN",
        "outputId": "8d68601f-0d45-4967-f0f5-b3556b12ef6b"
      },
      "outputs": [],
      "source": [
        "# write to file\n",
        "sink = root_dir+\"gold/\"\n",
        "\n",
        "write_name = sink+f\"hivedata__{pd.Timestamp.now().strftime('%Y-%m-%dT%Hh%Mm%Ss')}.parquet\"\n",
        "with fs.open(write_name, \"wb\") as f:\n",
        "    gold.to_parquet(f, index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L0HgqzY9wYgO",
        "outputId": "9fa8c967-f6fd-4e48-9c06-49feb7a2e457"
      },
      "outputs": [],
      "source": [
        "mssparkutils.session.stop()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "description": null,
    "kernelspec": {
      "display_name": "python",
      "name": "synapse_pyspark"
    },
    "language_info": {
      "name": "python"
    },
    "save_output": true,
    "synapse_widget": {
      "state": {},
      "version": "0.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
